{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391b97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "dados = pd.read_csv(\"df_filt.csv\")\n",
    "teste = pd.read_csv(\"df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926bd467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     mean_Back.Acc.X  std_Back.Acc.X  mean_Back.Acc.Y  \\\n",
      "segundo                                                                 \n",
      "2019-05-20 14:46:28         0.028276        0.087154        -0.154170   \n",
      "2019-05-20 14:46:29         0.016582        0.031741        -0.204888   \n",
      "2019-05-20 14:46:30         0.080908        0.054575        -0.197319   \n",
      "2019-05-20 14:46:31         0.038403        0.119151        -0.070952   \n",
      "2019-05-20 14:46:32        -0.071152        0.130153         0.333833   \n",
      "\n",
      "                     std_Back.Acc.Y  mean_Back.Acc.Z  std_Back.Acc.Z  \\\n",
      "segundo                                                                \n",
      "2019-05-20 14:46:28        0.047352         1.004082        0.048497   \n",
      "2019-05-20 14:46:29        0.025774         1.001001        0.026427   \n",
      "2019-05-20 14:46:30        0.035986         1.000967        0.056624   \n",
      "2019-05-20 14:46:31        0.118290         1.001909        0.085840   \n",
      "2019-05-20 14:46:32        0.135816         0.951445        0.072156   \n",
      "\n",
      "                     mean_Back.Gyr.X  std_Back.Gyr.X  mean_Back.Gyr.Y  \\\n",
      "segundo                                                                 \n",
      "2019-05-20 14:46:28        -3.768921        9.828624        -2.918091   \n",
      "2019-05-20 14:46:29        -1.986084        2.997144         3.546143   \n",
      "2019-05-20 14:46:30         3.765259        6.155347        -2.200318   \n",
      "2019-05-20 14:46:31        15.519410       10.597914         2.001343   \n",
      "2019-05-20 14:46:32         5.324707       28.298209        -5.427246   \n",
      "\n",
      "                     std_Back.Gyr.Y  ...  mean_Neck.Gyr.Y  std_Neck.Gyr.Y  \\\n",
      "segundo                              ...                                    \n",
      "2019-05-20 14:46:28       16.272527  ...        -0.877075        5.430156   \n",
      "2019-05-20 14:46:29        8.310131  ...         1.174316       10.328572   \n",
      "2019-05-20 14:46:30       18.405070  ...         9.719465       16.500603   \n",
      "2019-05-20 14:46:31       18.019022  ...       -27.293092       37.325750   \n",
      "2019-05-20 14:46:32       31.043027  ...       -14.387208       20.347985   \n",
      "\n",
      "                     mean_Neck.Gyr.Z  std_Neck.Gyr.Z  mean_Neck.Mag.X  \\\n",
      "segundo                                                                 \n",
      "2019-05-20 14:46:28        13.193360       15.220819        10.202636   \n",
      "2019-05-20 14:46:29       -28.212282       34.730823         4.494140   \n",
      "2019-05-20 14:46:30       -43.984939       11.737879         0.964409   \n",
      "2019-05-20 14:46:31        20.479738       70.322856        -4.842773   \n",
      "2019-05-20 14:46:32        61.991581       25.321502         3.099609   \n",
      "\n",
      "                     std_Neck.Mag.X  mean_Neck.Mag.Y  std_Neck.Mag.Y  \\\n",
      "segundo                                                                \n",
      "2019-05-20 14:46:28        0.750798        11.389160        0.792646   \n",
      "2019-05-20 14:46:29        2.946057        11.680664        1.161027   \n",
      "2019-05-20 14:46:30        1.338387         7.627719        2.090026   \n",
      "2019-05-20 14:46:31        3.841844         5.414062        2.249461   \n",
      "2019-05-20 14:46:32        4.306635        20.047851        3.776017   \n",
      "\n",
      "                     mean_Neck.Mag.Z  std_Neck.Mag.Z  \n",
      "segundo                                               \n",
      "2019-05-20 14:46:28       -30.165526        0.681770  \n",
      "2019-05-20 14:46:29       -31.787108        0.828379  \n",
      "2019-05-20 14:46:30       -30.084681        1.243119  \n",
      "2019-05-20 14:46:31       -28.177733        0.871606  \n",
      "2019-05-20 14:46:32       -31.866209        0.614967  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "dados[\"Timestamp\"] = pd.to_datetime(dados[\"Timestamp\"])\n",
    "dados[\"segundo\"] = dados[\"Timestamp\"].dt.floor(\"s\")\n",
    "\n",
    "teste[\"Timestamp\"] = pd.to_datetime(teste[\"Timestamp\"])\n",
    "teste[\"segundo\"] = teste[\"Timestamp\"].dt.floor(\"s\")\n",
    "\n",
    "dados_num = dados.drop(columns=[\"Type\", \"Position\", \"Breed\", \"Subject\", \"Timestamp\"])\n",
    "teste_num = teste.drop(columns=[\"Type\", \"Position\", \"Breed\", \"Subject\", \"Timestamp\"])\n",
    "\n",
    "grouped = dados_num.groupby(\"segundo\")\n",
    "test_grouped = teste_num.groupby(\"segundo\")\n",
    "\n",
    "test_features = pd.DataFrame()\n",
    "features = pd.DataFrame()\n",
    "\n",
    "for col in dados_num.columns[:-1]:\n",
    "    _ = grouped[col].describe()\n",
    "\n",
    "    features[f\"mean_{col}\"] = _[\"mean\"]\n",
    "    features[f\"std_{col}\"] = _[\"std\"]\n",
    "\n",
    "print(features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654addde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axis(ax:str, dataframe:pd.DataFrame) -> pd.DataFrame: \n",
    "    \"\"\"Filtra o Eixo de um dataframe\"\"\"\n",
    "    dataframe_ax = pd.DataFrame()\n",
    "    for col in dataframe.columns: \n",
    "        if col.endswith(ax):\n",
    "            dataframe_ax[col] = dataframe[col] \n",
    "    return dataframe_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1952f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axis_mean(ax: str, dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Retorna um Dataframe com com a média das médias e dos desvios padrões de um eixo específico\"\"\"\n",
    "    dataframe_ax_mean = pd.DataFrame()\n",
    "    dataframe_ax_std = pd.DataFrame()\n",
    "\n",
    "    for col in dataframe: \n",
    "        if col.endswith(ax):\n",
    "            if col.startswith(\"mean\"):\n",
    "                dataframe_ax_mean[col] = dataframe[col]\n",
    "            else: \n",
    "                dataframe_ax_std[col] = dataframe[col]\n",
    "    \n",
    "    dataframe_ax_mean = dataframe_ax_mean.mean(axis = 1 )\n",
    "    dataframe_ax_std = dataframe_ax_std.mean(axis = 1 )\n",
    "        \n",
    "    return pd.DataFrame({f\"mean_media_{ax}\": dataframe_ax_mean, f\"mean_Desviopadrao_{ax}\": dataframe_ax_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f0e73dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     soma_std_X\n",
      "segundo                        \n",
      "2019-05-20 14:46:28   24.397904\n",
      "2019-05-20 14:46:29   35.144755\n",
      "2019-05-20 14:46:30   43.419110\n",
      "2019-05-20 14:46:31   65.633140\n",
      "2019-05-20 14:46:32   66.202740\n",
      "2019-05-20 14:46:33  128.808974\n",
      "2019-05-20 14:46:34  104.035952\n",
      "2019-05-20 14:46:35   38.185583\n",
      "2019-05-20 14:46:36   19.563591\n",
      "2019-05-20 14:46:37   17.473988\n"
     ]
    }
   ],
   "source": [
    "def get_axis_sum(ax: str, dataframe: pd.DataFrame) -> pd.DataFrame: \n",
    "    \"\"\"Faz a soma do desvio padrão que acontece em um eixo em específico\"\"\"\n",
    "    dataframe_ax_std = pd.DataFrame()\n",
    "\n",
    "    for col in dataframe: \n",
    "        if col.endswith(ax):\n",
    "            if col.startswith(\"std\"):\n",
    "                dataframe_ax_std[col] = dataframe[col]\n",
    "            \n",
    "    dataframe_ax_sum_std = dataframe_ax_std.sum(axis = 1 )\n",
    "\n",
    "    return pd.DataFrame({f\"soma_std_{ax}\":dataframe_ax_sum_std})\n",
    "\n",
    "df = get_axis_sum(\"X\", features)\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afbbd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensor(sensor: str, dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    dataframe_sensor = pd.DataFrame()\n",
    "    for col in dataframe.columns: \n",
    "        if sensor in col: \n",
    "            dataframe_sensor[col] = dataframe[col]\n",
    "\n",
    "    return dataframe_sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509e10dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Neck.Gyr', 'Back.Gyr', 'Chest.Gyr', 'Back.Mag', 'Neck.Mag', 'Back.Acc', 'Neck.Acc', 'Chest.Mag', 'Chest.Acc'}\n"
     ]
    }
   ],
   "source": [
    "standing = dados[dados[\"Position\"] == \"standing\"]\n",
    "conjunto_sensores = set(col[:-2] for col in dados_num.drop(columns= \"segundo\").columns)\n",
    "\n",
    "eixos = (\"X\", \"Y\", \"Z\")\n",
    "\n",
    "dict_sensores = {}\n",
    "\n",
    "for sensor in conjunto_sensores:\n",
    "    df_sensor = get_sensor(sensor, standing)\n",
    "    dict_valores = {}\n",
    "\n",
    "    for ax in eixos:\n",
    "        col_df = get_axis(ax, df_sensor)\n",
    "\n",
    "        # caso 1: não existe esse eixo → col_df vazio\n",
    "        if col_df is None or len(col_df.columns if isinstance(col_df, pd.DataFrame) else col_df) == 0:\n",
    "            dict_valores[f\"mean_{ax}\"] = None\n",
    "            continue\n",
    "\n",
    "        # caso 2: veio DataFrame → pegar a primeira coluna\n",
    "        if isinstance(col_df, pd.DataFrame):\n",
    "            col_series = col_df.iloc[:, 0]\n",
    "        else:\n",
    "            col_series = col_df\n",
    "\n",
    "        dict_valores[f\"mean_{ax}\"] = float(col_series.mean())\n",
    "\n",
    "    dict_sensores[sensor] = dict_valores\n",
    "\n",
    "print(conjunto_sensores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "372d5ba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conjunto_sensores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sensor \u001b[38;5;129;01min\u001b[39;00m \u001b[43mconjunto_sensores\u001b[49m:\n\u001b[32m      2\u001b[39m     df_sensor = get_sensor(sensor, dados_num)\n\u001b[32m      3\u001b[39m     dist_euc_sensor = pd.DataFrame(index=dados_num.index)\n",
      "\u001b[31mNameError\u001b[39m: name 'conjunto_sensores' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for sensor in conjunto_sensores:\n",
    "    df_sensor = get_sensor(sensor, dados_num)\n",
    "    dist_euc_sensor = pd.DataFrame(index=dados_num.index)\n",
    "    for eixo in eixos:\n",
    "        serie_ax = (get_axis(eixo, df_sensor) - dict_sensores[sensor][f\"mean_{eixo}\"])**2\n",
    "        dist_euc_sensor[f\"{sensor}_{eixo}\"] = serie_ax\n",
    "        dist_euc_sensor[f\"dist_euc_{sensor}\"] = np.sqrt(dist_euc_sensor.sum(axis=1))\n",
    "        dist_euc_sensor.drop(columns=[f\"{sensor}_{eixo}\"], inplace=True)\n",
    "\n",
    "        features[f\"dist_euc_{sensor}\"] = dist_euc_sensor[f\"dist_euc_{sensor}\"]\n",
    "\n",
    "for eixo in eixos:\n",
    "    df_axis_sum = get_axis_sum(eixo, features)\n",
    "    features[f\"soma_std_{eixo}\"] = df_axis_sum[f\"soma_std_{eixo}\"]\n",
    "\n",
    "for sensor in conjunto_sensores:\n",
    "    _ = pd.DataFrame(index=features.index)\n",
    "    _[f\"sum_std_{sensor}\"] = 0\n",
    "    for col in features.columns:\n",
    "        if f\"std_{sensor}\" in col:\n",
    "            _[f\"sum_std_{sensor}\"] += features[col]\n",
    "\n",
    "    features[f\"sum_std_{sensor}\"] = _[f\"sum_std_{sensor}\"]\n",
    "\n",
    "features[\"Position\"] = dados[\"Position\"]\n",
    "\n",
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cd8b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mfeatures\u001b[49m.columns)\n",
      "\u001b[31mNameError\u001b[39m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(features.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
